{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "x_digits = digits.data\n",
    "y_digits = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the data set into 70% training data and 30% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_digits_train, x_digits_test, y_digits_train, y_digits_test = train_test_split(x_digits, y_digits, test_size=0.3, random_state=42)\n",
    "x_digits_train, x_digits_test = x_digits_train/16.0, x_digits_test/16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-clustering against ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class EM_Gauss():\n",
    "    def __init__(self, epsilon = 1e-2, threshold = 1e-3):\n",
    "        self.epsilon = epsilon\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # density function of the normal distribution\n",
    "    def pdf_vector(self, x, mean, var):\n",
    "        return 1 / np.sqrt(2 * np.pi * var) * np.exp(-1 / (2 * var) * (x - mean) ** 2)\n",
    "    \n",
    "    # fitting the model using EM algorithm\n",
    "    def fit(self, data, target, labels):\n",
    "        data = np.array(data)\n",
    "        self.labels = labels\n",
    "        nb_samples, nb_features = np.shape(data)\n",
    "        self.priors = np.ones(labels)/labels\n",
    "            \n",
    "        # Initiliazing means and standard deviations\n",
    "        self.means = np.empty([labels, nb_features])\n",
    "        self.std = np.empty([labels, nb_features])\n",
    "        \n",
    "        for k in range(labels):\n",
    "            self.means[k] = np.mean(data[target == k], axis = 0)\n",
    "            self.std[k] = np.var(data[target == k], axis = 0)\n",
    "        self.std += self.epsilon\n",
    "        \n",
    "        # Weights\n",
    "        proba = np.empty([labels, nb_samples])\n",
    "        weights = np.empty([labels, nb_samples])\n",
    "        prev_priors = np.zeros(labels)\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            # E step\n",
    "            for k in range(labels):\n",
    "                proba[k,:] = np.prod(self.pdf_vector(data, self.means[k], self.std[k]), axis=1)\n",
    "                weights[k, :] = self.priors[k] * proba[k,:]\n",
    "            weights = weights / (np.sum(weights, axis = 0))\n",
    "\n",
    "            # M step\n",
    "            rk = np.sum(weights, axis = 1)\n",
    "            prev_priors = self.priors\n",
    "            self.priors = rk / nb_samples\n",
    "                   \n",
    "            # Updation means and std\n",
    "            for k in range(labels):\n",
    "                self.means[k] = np.sum(weights[k, :].reshape(-1,1) * data, axis = 0) / rk[k]\n",
    "                self.std[k] = np.diag( ( weights[k, :].reshape(-1, 1) * (data - self.means[k]) ).T @ (data - self.means[k]) / rk[k] )\n",
    "            self.std += self.epsilon\n",
    "            \n",
    "            # Condition of stop (comparing prior probabilities with previous priors)\n",
    "            if (np.linalg.norm(prev_priors - self.priors) < self.threshold):\n",
    "                break\n",
    "        \n",
    "\n",
    "    # Predicting the labels for given features\n",
    "    def predict(self, test):\n",
    "        x = np.array(test)\n",
    "        length = x.shape[0]\n",
    "        y_hat = np.zeros((length, ))  \n",
    "        for i in range(length):\n",
    "            proba = dict()\n",
    "            probas = []\n",
    "            for label in range(self.labels):          \n",
    "                product = np.longdouble(-self.priors[label])\n",
    "                for j in range(x.shape[1]):\n",
    "                      product *= self.pdf_vector(x[i][j], self.means[label][j], math.sqrt(self.std[label][j]))\n",
    "                heapq.heappush(probas, product)\n",
    "                proba[product] = label\n",
    "            \n",
    "            y_hat[i] = proba[probas[0]]\n",
    "        return y_hat\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"EM_Gauss(epsilon={})\".format(self.epsilon)\n",
    "    def __str__(self):\n",
    "        return \"EM_Gauss(epsilon={})\".format(self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.01625033e-03 2.61176369e-01 8.21139942e-01\n",
      "  7.23069387e-01 1.90547569e-01 1.52437550e-03 6.19582336e-32\n",
      "  2.63656113e-48 5.74181436e-02 8.01317027e-01 8.40956803e-01\n",
      "  7.25103042e-01 7.14936395e-01 5.99587694e-02 3.09791168e-32\n",
      "  2.53799273e-31 2.40343203e-01 9.03454912e-01 3.20127848e-01\n",
      "  1.26523764e-01 7.60161927e-01 2.16969480e-01 4.83261844e-31\n",
      "  1.26899636e-31 3.32821983e-01 7.93701072e-01 1.13320879e-01\n",
      "  1.01625033e-02 5.69108637e-01 4.12090148e-01 4.83261844e-31\n",
      "  0.00000000e+00 3.63310090e-01 7.21039174e-01 5.28509953e-02\n",
      "  1.52437549e-03 5.37096772e-01 4.57821997e-01 0.00000000e+00\n",
      "  9.66523689e-31 2.19001946e-01 8.32318064e-01 9.90922482e-02\n",
      "  7.77450128e-02 7.02746174e-01 3.71441289e-01 2.46081124e-43\n",
      "  3.86609476e-30 4.72556402e-02 8.23676383e-01 6.30593006e-01\n",
      "  6.50918012e-01 8.46545596e-01 1.55486391e-01 2.77732521e-08\n",
      "  5.59887651e-49 5.92750330e-23 2.57111382e-01 8.53150034e-01\n",
      "  8.46546180e-01 3.37399962e-01 1.57519357e-02 2.08299391e-08]\n",
      " [0.00000000e+00 6.07724303e-09 8.67793027e-02 5.71971051e-01\n",
      "  7.93162680e-01 3.91513141e-01 4.02368731e-02 1.75241137e-18\n",
      "  1.04566704e-29 3.53987265e-03 2.20023086e-01 8.06156003e-01\n",
      "  9.25416894e-01 6.08668253e-01 7.61785210e-02 1.50085327e-15\n",
      "  5.03457678e-23 3.30514595e-02 3.59194620e-01 8.89864106e-01\n",
      "  8.98329253e-01 5.64393884e-01 3.99655179e-02 2.43383145e-18\n",
      "  3.40221520e-07 1.05933421e-01 4.74323304e-01 8.78437826e-01\n",
      "  9.34479457e-01 4.12507716e-01 1.04087667e-02 4.73256479e-46\n",
      "  0.00000000e+00 5.94275064e-02 4.66056943e-01 8.40495659e-01\n",
      "  9.05298216e-01 2.81115159e-01 4.65314690e-03 0.00000000e+00\n",
      "  5.19541884e-27 6.47042460e-02 4.95558911e-01 7.46675065e-01\n",
      "  8.34527920e-01 3.21898279e-01 1.31887640e-02 2.67383245e-31\n",
      "  6.21250011e-10 1.49229437e-02 3.65071818e-01 7.52125086e-01\n",
      "  8.32229261e-01 4.10646123e-01 5.35049229e-02 1.03843851e-04\n",
      "  2.07083337e-10 5.01015558e-04 9.37253663e-02 5.41181690e-01\n",
      "  8.25023444e-01 4.37661857e-01 8.47382921e-02 1.01162069e-03]\n",
      " [0.00000000e+00 5.92706897e-02 6.23491407e-01 9.09391169e-01\n",
      "  5.12773654e-01 8.85069997e-02 5.79029231e-09 4.20105182e-32\n",
      "  1.86660512e-03 3.30576826e-01 8.52467271e-01 7.79385986e-01\n",
      "  7.13900981e-01 2.55954783e-01 4.50247371e-03 9.70854887e-25\n",
      "  9.33302569e-04 2.88137506e-01 4.99000988e-01 3.54878585e-01\n",
      "  7.13359223e-01 2.80591202e-01 9.85054197e-03 3.64724330e-29\n",
      "  4.09939244e-12 5.31964824e-02 1.64106990e-01 3.98748690e-01\n",
      "  7.55900433e-01 2.17646201e-01 6.10931947e-03 5.93940224e-75\n",
      "  0.00000000e+00 1.40002440e-03 9.21460467e-02 5.84089126e-01\n",
      "  6.58946302e-01 1.42233894e-01 2.84428793e-03 0.00000000e+00\n",
      "  1.07727667e-51 1.25868681e-02 2.70209069e-01 6.81303889e-01\n",
      "  4.97428467e-01 1.71352078e-01 5.95680561e-02 4.66665964e-04\n",
      "  7.05670684e-13 7.03696300e-02 6.78252269e-01 8.61365204e-01\n",
      "  7.50109247e-01 7.01151275e-01 4.87899180e-01 6.24150864e-02\n",
      "  2.35223561e-13 5.31955466e-02 6.45876474e-01 9.16735674e-01\n",
      "  8.52346325e-01 7.70630070e-01 5.68033322e-01 1.77127815e-01]\n",
      " [0.00000000e+00 4.33040212e-02 5.60652195e-01 9.08129633e-01\n",
      "  8.63594927e-01 4.21898912e-01 3.18321397e-02 3.95550471e-20\n",
      "  1.05444199e-03 2.95455532e-01 8.07918401e-01 5.54509969e-01\n",
      "  7.47734921e-01 7.30179977e-01 9.56162437e-02 9.69786913e-07\n",
      "  5.27220993e-04 1.42591683e-01 2.61690826e-01 2.36745246e-01\n",
      "  7.82806522e-01 5.81061183e-01 3.81228058e-02 1.44464468e-47\n",
      "  4.61045998e-53 5.78481126e-03 8.85449215e-02 5.74359557e-01\n",
      "  8.99541706e-01 4.12219325e-01 1.14354278e-02 3.80069027e-71\n",
      "  0.00000000e+00 5.27213622e-03 3.97968063e-02 2.75382659e-01\n",
      "  7.05504072e-01 8.04356716e-01 1.63391972e-01 0.00000000e+00\n",
      "  6.58165069e-71 3.05642536e-02 8.45145655e-02 1.68622189e-02\n",
      "  1.97905510e-01 7.88774961e-01 4.34545131e-01 2.93990212e-26\n",
      "  1.80844689e-33 6.78662853e-02 4.95159354e-01 3.83136519e-01\n",
      "  5.11021879e-01 8.77784097e-01 3.78984015e-01 1.64571079e-03\n",
      "  6.02815630e-34 3.25718503e-02 6.12257188e-01 9.30940117e-01\n",
      "  8.91201690e-01 5.45568612e-01 6.38403387e-02 3.20332031e-05]\n",
      " [0.00000000e+00 7.00646294e-32 1.11597625e-02 4.24506059e-01\n",
      "  7.55539344e-01 1.42072204e-01 1.13960466e-03 5.61198798e-04\n",
      "  1.56875360e-34 1.52821985e-08 1.77202784e-01 8.49951544e-01\n",
      "  5.63037070e-01 9.46488207e-02 4.97185635e-02 1.90790898e-02\n",
      "  9.72913182e-29 2.88573093e-02 6.36144155e-01 7.56007533e-01\n",
      "  2.77483710e-01 3.17149142e-01 2.27718450e-01 1.68342350e-02\n",
      "  1.52533757e-08 2.73469878e-01 9.16309616e-01 3.89555663e-01\n",
      "  3.80418215e-01 6.79721486e-01 4.03423370e-01 1.12229604e-03\n",
      "  0.00000000e+00 5.53355158e-01 9.29884413e-01 5.83229427e-01\n",
      "  7.71640697e-01 9.01026958e-01 3.37163725e-01 0.00000000e+00\n",
      "  8.41722032e-03 4.02267679e-01 7.30264985e-01 7.74049500e-01\n",
      "  9.18916824e-01 7.01666922e-01 1.05391333e-01 5.69039039e-28\n",
      "  5.05033219e-03 7.60200338e-02 1.98116003e-01 4.79166991e-01\n",
      "  8.79214635e-01 3.10324754e-01 1.64899990e-03 1.17648511e-26\n",
      "  1.35326210e-20 5.61148024e-04 1.48035520e-02 4.63259845e-01\n",
      "  7.99606554e-01 1.40674792e-01 1.68981391e-10 2.75759979e-41]\n",
      " [0.00000000e+00 7.13711412e-02 6.39320681e-01 8.17406287e-01\n",
      "  8.73800409e-01 7.46854295e-01 2.35487061e-01 1.15173136e-03\n",
      "  5.75864044e-04 2.90122585e-01 9.36298790e-01 7.58881345e-01\n",
      "  5.21160840e-01 3.83025447e-01 1.22507735e-01 5.76619933e-04\n",
      "  1.15172565e-03 3.87645041e-01 8.97763994e-01 3.33884592e-01\n",
      "  8.57636194e-02 1.41629248e-02 9.99581706e-07 1.38064810e-35\n",
      "  1.15132224e-03 3.22549661e-01 9.02946967e-01 7.59590762e-01\n",
      "  5.14399951e-01 1.91792347e-01 1.34427944e-02 3.36623177e-58\n",
      "  0.00000000e+00 1.21158548e-01 4.95735883e-01 5.87957947e-01\n",
      "  5.85640743e-01 4.19399663e-01 8.36018676e-02 0.00000000e+00\n",
      "  7.16372502e-37 1.29147962e-02 7.07119690e-02 2.65458833e-01\n",
      "  4.90786952e-01 4.81822521e-01 1.23062437e-01 8.16357330e-23\n",
      "  1.70072505e-30 6.04372484e-02 3.35301192e-01 5.22925529e-01\n",
      "  6.88945951e-01 4.32213921e-01 6.33276036e-02 6.07380896e-15\n",
      "  5.66908349e-31 6.56318576e-02 6.82746980e-01 9.18766652e-01\n",
      "  5.57338570e-01 1.17021307e-01 2.32036861e-03 5.09386229e-20]\n",
      " [0.00000000e+00 1.10121715e-17 6.41847098e-02 6.90898888e-01\n",
      "  6.10846271e-01 8.01238527e-02 2.49564298e-15 8.07218643e-51\n",
      "  7.77907822e-38 1.93284889e-03 4.05964029e-01 9.21300987e-01\n",
      "  4.25604139e-01 4.23671841e-02 1.15015210e-15 1.99494816e-46\n",
      "  2.14238656e-21 3.96056400e-02 7.36732225e-01 6.44600956e-01\n",
      "  8.26317973e-02 4.80299436e-03 2.88965837e-16 5.98316904e-46\n",
      "  2.06577956e-21 1.28434193e-01 8.39292942e-01 5.40839813e-01\n",
      "  2.53295549e-01 1.21626236e-01 8.20144780e-03 9.62523387e-53\n",
      "  0.00000000e+00 2.10025915e-01 9.11190662e-01 8.14835519e-01\n",
      "  7.67262924e-01 6.26224276e-01 1.74778629e-01 0.00000000e+00\n",
      "  1.48299105e-16 1.16384681e-01 9.00923410e-01 7.06036300e-01\n",
      "  3.78478633e-01 6.29457876e-01 5.68847665e-01 1.93184484e-02\n",
      "  4.32073820e-24 1.15910249e-02 6.30151603e-01 8.10664997e-01\n",
      "  3.74869019e-01 7.07271023e-01 6.78118309e-01 5.13384614e-02\n",
      "  8.83748525e-52 5.39044896e-22 8.32245431e-02 6.63362998e-01\n",
      "  9.45483987e-01 8.29920364e-01 2.94211084e-01 1.42289762e-02]\n",
      " [0.00000000e+00 9.68041342e-03 3.03428273e-01 7.91970216e-01\n",
      "  8.60968191e-01 6.74403884e-01 3.48213811e-01 7.01584289e-02\n",
      "  2.26033430e-31 5.62245639e-02 6.35642086e-01 7.26514808e-01\n",
      "  6.35667682e-01 7.60542920e-01 3.76713259e-01 4.45756002e-02\n",
      "  8.10850738e-22 5.88824050e-02 3.56830472e-01 1.81924177e-01\n",
      "  4.17799449e-01 7.15004506e-01 2.39624082e-01 1.04978272e-02\n",
      "  7.31611987e-14 5.95199672e-02 3.27407998e-01 4.31295418e-01\n",
      "  7.58913086e-01 7.46292281e-01 3.01456205e-01 4.19897038e-04\n",
      "  0.00000000e+00 8.89259243e-02 5.27331125e-01 8.01386972e-01\n",
      "  9.04972862e-01 6.58189950e-01 2.38512206e-01 0.00000000e+00\n",
      "  3.49539406e-21 6.63311319e-02 3.12399868e-01 6.90966320e-01\n",
      "  7.06345785e-01 2.67916232e-01 3.69160090e-02 1.18475683e-44\n",
      "  1.06308415e-22 6.10595258e-03 1.80134811e-01 7.44756570e-01\n",
      "  4.29319611e-01 3.17848332e-02 4.01868143e-11 5.82123837e-32\n",
      "  3.54361382e-23 8.83948167e-03 3.75043413e-01 7.53687334e-01\n",
      "  1.85085773e-01 5.36038559e-03 6.13948620e-17 8.09522215e-35]\n",
      " [0.00000000e+00 1.50382810e-02 4.00589047e-01 7.66283456e-01\n",
      "  7.56734285e-01 4.04780108e-01 3.09162061e-02 1.24021805e-15\n",
      "  6.05057834e-08 1.34491061e-01 8.38103852e-01 6.94361436e-01\n",
      "  6.00263082e-01 7.35867669e-01 1.58514446e-01 4.78808825e-06\n",
      "  3.06752684e-08 1.75803484e-01 7.54411710e-01 4.13857650e-01\n",
      "  4.88859729e-01 7.15513831e-01 1.32748182e-01 7.88008168e-13\n",
      "  2.44152431e-10 7.07469672e-02 5.54893917e-01 8.13861763e-01\n",
      "  8.03284692e-01 4.05271644e-01 2.69052198e-02 2.03960277e-36\n",
      "  0.00000000e+00 2.53754113e-02 4.00605062e-01 8.40463470e-01\n",
      "  7.66089820e-01 2.62336885e-01 8.26389352e-03 0.00000000e+00\n",
      "  1.14287605e-31 5.81017548e-02 5.82922916e-01 5.48522560e-01\n",
      "  5.56836146e-01 4.85525690e-01 8.21281914e-02 3.87411288e-10\n",
      "  1.43054553e-03 7.99683782e-02 6.60277066e-01 5.30848936e-01\n",
      "  5.34963696e-01 5.57035619e-01 1.29975012e-01 3.78992735e-04\n",
      "  4.76848511e-04 1.50127808e-02 4.06723279e-01 8.24749519e-01\n",
      "  7.66412227e-01 3.75065044e-01 4.65590975e-02 6.18553632e-08]\n",
      " [0.00000000e+00 6.95584601e-03 3.10883321e-01 6.37233071e-01\n",
      "  6.87086012e-01 4.39936156e-01 1.23809593e-01 3.84305391e-03\n",
      "  3.20224152e-13 1.15786517e-01 6.85683443e-01 5.87430565e-01\n",
      "  6.54538864e-01 7.50750421e-01 1.82789899e-01 7.19968515e-03\n",
      "  3.19111344e-13 2.17163450e-01 7.25990013e-01 4.18680460e-01\n",
      "  5.20428307e-01 8.81611294e-01 2.15432755e-01 3.39847221e-03\n",
      "  9.21285584e-29 1.40370370e-01 6.29988423e-01 6.85296031e-01\n",
      "  7.88472497e-01 9.04933200e-01 2.47641632e-01 2.06543975e-21\n",
      "  0.00000000e+00 2.28859862e-02 2.03937112e-01 2.90238840e-01\n",
      "  3.37676022e-01 7.91183619e-01 3.03714616e-01 0.00000000e+00\n",
      "  2.32136536e-55 1.16745879e-02 2.32582720e-02 1.39491674e-02\n",
      "  1.66246551e-01 6.79076508e-01 3.80448300e-01 5.97483030e-30\n",
      "  1.44378367e-34 2.92846119e-02 3.45654208e-01 2.51071100e-01\n",
      "  3.88090542e-01 7.11242731e-01 3.70136019e-01 7.20163906e-03\n",
      "  4.81261224e-35 4.23993377e-03 3.12666545e-01 6.48581170e-01\n",
      "  8.39765808e-01 6.51082302e-01 1.79316776e-01 8.69949011e-03]]\n"
     ]
    }
   ],
   "source": [
    "classifier = EM_Gauss()\n",
    "classifier.fit(x_digits_train, y_digits_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = classifier.predict(x_digits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:  0.7750072213204816\n",
      "homogeneity:  0.7662787437951897\n",
      "mutual_info:  0.7628979204904448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/anaconda3/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score, adjusted_mutual_info_score\n",
    "\n",
    "print(\"Completeness: \", completeness_score(y_digits_train, y_hat))\n",
    "print(\"homogeneity: \", homogeneity_score(y_digits_train, y_hat))\n",
    "print(\"mutual_info: \", adjusted_mutual_info_score(y_digits_train, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[124   0   0   0   1   0   0   0   0   0]\n",
      " [  0  99  10   0   0   1   8   0   0  14]\n",
      " [  1   7 114   3   0   0   0   1   4   0]\n",
      " [  0   1   0 117   0   1   0   6   3   1]\n",
      " [  0   3   0   0 111   0   0   4   3   0]\n",
      " [  2   0   0  10   0 102   0   0   1   1]\n",
      " [  0   1   0   0   0   0 127   0   0   0]\n",
      " [  0   1   0   0   0   0   0 121   2   0]\n",
      " [  0  32   2   4   0   1   5   1  85   1]\n",
      " [  3   1   0  50   0   1   0   8   3  55]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       125\n",
      "           1       0.68      0.75      0.71       132\n",
      "           2       0.90      0.88      0.89       130\n",
      "           3       0.64      0.91      0.75       129\n",
      "           4       0.99      0.92      0.95       121\n",
      "           5       0.96      0.88      0.92       116\n",
      "           6       0.91      0.99      0.95       128\n",
      "           7       0.86      0.98      0.91       124\n",
      "           8       0.84      0.65      0.73       131\n",
      "           9       0.76      0.45      0.57       121\n",
      "\n",
      "    accuracy                           0.84      1257\n",
      "   macro avg       0.85      0.84      0.84      1257\n",
      "weighted avg       0.85      0.84      0.83      1257\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_digits_train, y_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_digits_train, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means against ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=10, random_state=0)\n",
    "# fitting the model\n",
    "cluster = model.fit(x_digits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_digits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:  0.7360914843284315\n",
      "homogeneity:  0.7285326270567938\n",
      "mutual_info:  0.7246048855466674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/anaconda3/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Completeness: \", completeness_score(y_digits_train, y_hat))\n",
    "print(\"homogeneity: \", homogeneity_score(y_digits_train, y_hat))\n",
    "print(\"mutual_info: \", adjusted_mutual_info_score(y_digits_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM against k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM_Kmeans():\n",
    "    def __init__(self, epsilon = 1e-2):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, data, target, labels):\n",
    "        data = np.array(data)\n",
    "        self.labels = labels\n",
    "        nb_samples, nb_features = np.shape(data)            \n",
    "        self.means = np.empty([labels, nb_features])\n",
    "        self.z = np.empty(nb_samples)\n",
    "\n",
    "        for k in range(labels):\n",
    "            self.means[k] = np.mean(data[target == k], axis = 0)\n",
    "        \n",
    "        prev_means = np.zeros((labels, nb_features))\n",
    "        while np.linalg.norm(prev_means - self.means) > 1e-6:\n",
    "            \n",
    "            prev_means = np.array(self.means)\n",
    "            # E step\n",
    "            for i in range(nb_samples):\n",
    "                distance = []\n",
    "                index = dict()\n",
    "                for k in range(labels):\n",
    "                    norm = np.linalg.norm(data[i] - self.means[k])\n",
    "                    heapq.heappush(distance, norm**2)\n",
    "                    index[norm**2] = k\n",
    "                self.z[i] = index[distance[0]]\n",
    "            # M step \n",
    "            for k in range(labels):\n",
    "                self.means[k] = np.mean(data[self.z == k], axis = 0)\n",
    "\n",
    "    def predict(self, test):\n",
    "        x = np.array(test)\n",
    "        length = x.shape[0]\n",
    "        y_hat = np.zeros((length, ))  \n",
    "        for i in range(length):\n",
    "            proba = dict()\n",
    "            probas = []\n",
    "            for label in range(self.labels):          \n",
    "                product = np.longdouble(-self.priors[label])\n",
    "                for j in range(x.shape[1]):\n",
    "                      product *= self.pdf_vector(x[i][j], self.means[label][j], math.sqrt(self.std[label][j]))\n",
    "                heapq.heappush(probas, product)\n",
    "                proba[product] = label\n",
    "            \n",
    "            y_hat[i] = proba[probas[0]]\n",
    "        return y_hat\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"EM_Kmeans(epsilon={})\".format(self.epsilon)\n",
    "    def __str__(self):\n",
    "        return \"EM_Kmeans(epsilon={})\".format(self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EM_Kmeans()\n",
    "classifier.fit(x_digits_train, y_digits_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_digits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:  0.7360914843284315\n",
      "homogeneity:  0.7285326270567938\n",
      "mutual_info:  0.7246048855466674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/anaconda3/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Completeness: \", completeness_score(y_digits_train, y_hat))\n",
    "print(\"homogeneity: \", homogeneity_score(y_digits_train, y_hat))\n",
    "print(\"mutual_info: \", adjusted_mutual_info_score(y_digits_train, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:  0.769142602293317\n",
      "homogeneity:  0.7570724943188667\n",
      "mutual_info:  0.7483708732266358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/anaconda3/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:746: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# classifier = EM_Kmeans()\n",
    "# classifier.fit(x_digits_test, y_digits_test, 10)\n",
    "y_hat = model.predict(x_digits_test)\n",
    "print(\"Completeness: \", completeness_score(y_digits_test, y_hat))\n",
    "print(\"homogeneity: \", homogeneity_score(y_digits_test, y_hat))\n",
    "print(\"mutual_info: \", adjusted_mutual_info_score(y_digits_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
