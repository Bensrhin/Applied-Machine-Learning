{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "x_digits = digits.data\n",
    "y_digits = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the data set into 70% training data and 30% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_digits_train, x_digits_test, y_digits_train, y_digits_test = train_test_split(x_digits, y_digits, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn digits summarised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your data set to contain only three values for the attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for 'dark', 1 for 'grey' and 2 for 'light',\n",
    "X = np.array(x_digits)\n",
    "for i in range(len(x_digits)):\n",
    "    for j in range(64):\n",
    "        if x_digits[i,j] < 5:\n",
    "            X[i,j] = 0\n",
    "        elif x_digits[i,j] > 10:\n",
    "            X[i,j] = 2\n",
    "        else:\n",
    "            X[i,j] = 1            \n",
    "# Splitting the new data\n",
    "x_sum_train, x_sum_test, y_sum_train, y_sum_test = train_test_split(X, y_digits, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST_Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "filelist = sorted(glob.glob('MNIST_Light/*/*.png'))\n",
    "#x = np.array([np.array(Image.open(fname).resize((8,8))) for fname in filelist])\n",
    "x = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "\n",
    "samples_per_class = 500\n",
    "number_of_classes = 10\n",
    "\n",
    "y = np.zeros(number_of_classes * samples_per_class,dtype=int)\n",
    "for cls in range(1, number_of_classes):\n",
    "    y[(cls*500):(cls+1)*500] = cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the set into 70% training and 30% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One flattened array per image && the normalization of pixels from [0 ... 255] to [0.0 ... 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalised = train_features.reshape(3500, 400)/1.0\n",
    "test_normalised = test_features.reshape(1500, 400)/1.0\n",
    "x_light_train, x_light_test, y_light_train, y_light_test =  train_normalised, test_normalised, train_labels, test_labels\n",
    "x_norm_train, x_norm_test = x_light_train/255.0, x_light_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Centroid Classifier (NCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class NCC:\n",
    "    def __init__(self):\n",
    "        self.centroids = dict()\n",
    "        self.nbLabels = dict()\n",
    "    \n",
    "    # The NCC fit method should simply compute \n",
    "    # the mean values over the attribute values of the examples for each class\n",
    "    def fit(self, data, target):\n",
    "        data = np.array(data)\n",
    "        target = np.array(target)\n",
    "        \n",
    "        for i in range(data.shape[0]):\n",
    "            if target[i] not in self.centroids:\n",
    "                self.centroids[target[i]] = data[i]\n",
    "                self.nbLabels[target[i]] = 1\n",
    "            else:\n",
    "                self.centroids[target[i]] += data[i]\n",
    "                self.nbLabels[target[i]] += 1\n",
    "        for label in self.nbLabels:\n",
    "            self.centroids[label] /= self.nbLabels[label]\n",
    "    \n",
    "    # Prediction is then done by finding \n",
    "    # the argmin over the distances from the class centroids for each sample\n",
    "    def predict(self, test):\n",
    "        x = np.array(test)\n",
    "        length = x.shape[0]\n",
    "        y_hat = np.zeros((length, ))  \n",
    "        for i in range(length):\n",
    "            distance = dict()\n",
    "            distances = []\n",
    "            for label in self.nbLabels:\n",
    "                norm = np.linalg.norm(x[i]-self.centroids[label])\n",
    "                heapq.heappush(distances, norm)\n",
    "                distance[norm] = label\n",
    "            y_hat[i] = distance[distances[0]]\n",
    "        return y_hat\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"NCC()\"\n",
    "    def __str__(self):\n",
    "        return \"NCC()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[52  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 35  7  0  0  0  0  0  4  4]\n",
      " [ 0  1 43  1  0  0  0  0  2  0]\n",
      " [ 0  0  0 48  0  0  0  1  4  1]\n",
      " [ 0  3  0  0 55  0  0  2  0  0]\n",
      " [ 0  0  0  0  1 52  1  0  0 12]\n",
      " [ 1  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 54  0  0]\n",
      " [ 0  3  0  0  0  1  0  0 38  1]\n",
      " [ 0  1  0  1  1  1  0  3  1 51]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        53\n",
      "           1       0.81      0.70      0.75        50\n",
      "           2       0.86      0.91      0.89        47\n",
      "           3       0.96      0.89      0.92        54\n",
      "           4       0.96      0.92      0.94        60\n",
      "           5       0.93      0.79      0.85        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       0.90      0.98      0.94        55\n",
      "           8       0.78      0.88      0.83        43\n",
      "           9       0.74      0.86      0.80        59\n",
      "\n",
      "    accuracy                           0.89       540\n",
      "   macro avg       0.89      0.89      0.89       540\n",
      "weighted avg       0.89      0.89      0.89       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc = NCC()\n",
    "ncc.fit(x_digits_train, y_digits_train)\n",
    "y_hat = ncc.predict(x_digits_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_digits_test, y_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_digits_test, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[51  0  0  0  1  1  0  0  0  0]\n",
      " [ 0 33  6  0  0  1  0  0  6  4]\n",
      " [ 0  3 41  1  0  0  0  0  2  0]\n",
      " [ 0  0  0 46  0  0  0  2  4  2]\n",
      " [ 0  3  0  0 55  0  0  2  0  0]\n",
      " [ 0  0  0  0  1 53  2  0  0 10]\n",
      " [ 1  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 55  0  0]\n",
      " [ 0  2  0  0  0  1  0  0 37  3]\n",
      " [ 0  1  0  2  1  1  0  3  1 50]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        53\n",
      "           1       0.79      0.66      0.72        50\n",
      "           2       0.87      0.87      0.87        47\n",
      "           3       0.94      0.85      0.89        54\n",
      "           4       0.95      0.92      0.93        60\n",
      "           5       0.93      0.80      0.86        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       0.89      1.00      0.94        55\n",
      "           8       0.74      0.86      0.80        43\n",
      "           9       0.72      0.85      0.78        59\n",
      "\n",
      "    accuracy                           0.88       540\n",
      "   macro avg       0.88      0.88      0.87       540\n",
      "weighted avg       0.88      0.88      0.88       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc = NCC()\n",
    "ncc.fit(x_sum_train, y_sum_train)\n",
    "y_sum_hat = ncc.predict(x_sum_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_sum_test, y_sum_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_sum_test, y_sum_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST_Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[150   0   2   0   0   6   3   1   2   0]\n",
      " [  0 148   0   0   0   2   0   0   2   0]\n",
      " [  0  15 113   8   2   3   3   1   8   2]\n",
      " [  1   5   8 117   1   7   1   2   8   4]\n",
      " [  1   4   2   0 108   0   3   0   1  24]\n",
      " [  3   9   0  24   4  97   2   0   1   1]\n",
      " [  3   6   2   0   4   5 123   0   0   0]\n",
      " [  1  14   2   0   6   1   0 127   1   6]\n",
      " [  3   6   4   8   0  12   1   0  95   3]\n",
      " [  3   0   1   1  19   2   1   3   2 126]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       164\n",
      "           1       0.71      0.97      0.82       152\n",
      "           2       0.84      0.73      0.78       155\n",
      "           3       0.74      0.76      0.75       154\n",
      "           4       0.75      0.76      0.75       143\n",
      "           5       0.72      0.69      0.70       141\n",
      "           6       0.90      0.86      0.88       143\n",
      "           7       0.95      0.80      0.87       158\n",
      "           8       0.79      0.72      0.75       132\n",
      "           9       0.76      0.80      0.78       158\n",
      "\n",
      "    accuracy                           0.80      1500\n",
      "   macro avg       0.81      0.80      0.80      1500\n",
      "weighted avg       0.81      0.80      0.80      1500\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc = NCC()\n",
    "ncc.fit(x_light_train, y_light_train)\n",
    "y_light_hat = ncc.predict(x_light_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_light_test, y_light_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_light_test, y_light_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST_Light: Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[150   0   2   0   0   6   3   1   2   0]\n",
      " [  0 148   0   0   0   2   0   0   2   0]\n",
      " [  0  15 113   8   2   3   3   1   8   2]\n",
      " [  1   5   8 117   1   7   1   2   8   4]\n",
      " [  1   4   2   0 108   0   3   0   1  24]\n",
      " [  3   9   0  24   4  97   2   0   1   1]\n",
      " [  3   6   2   0   4   5 123   0   0   0]\n",
      " [  1  14   2   0   6   1   0 127   1   6]\n",
      " [  3   6   4   8   0  12   1   0  95   3]\n",
      " [  3   0   1   1  19   2   1   3   2 126]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       164\n",
      "           1       0.71      0.97      0.82       152\n",
      "           2       0.84      0.73      0.78       155\n",
      "           3       0.74      0.76      0.75       154\n",
      "           4       0.75      0.76      0.75       143\n",
      "           5       0.72      0.69      0.70       141\n",
      "           6       0.90      0.86      0.88       143\n",
      "           7       0.95      0.80      0.87       158\n",
      "           8       0.79      0.72      0.75       132\n",
      "           9       0.76      0.80      0.78       158\n",
      "\n",
      "    accuracy                           0.80      1500\n",
      "   macro avg       0.81      0.80      0.80      1500\n",
      "weighted avg       0.81      0.80      0.80      1500\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc = NCC()\n",
    "ncc.fit(x_norm_train, y_light_train)\n",
    "y_light_hat = ncc.predict(x_norm_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_light_test, y_light_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_light_test, y_light_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian Classifier (NBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class NBC:\n",
    "    def __init__(self, alpha = 0):\n",
    "        self.condition = dict()\n",
    "        self.nbLabels = dict()\n",
    "        self.prior = dict()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, data, target):\n",
    "        data = np.array(data)\n",
    "        target = np.array(target)\n",
    "        \n",
    "        for i in range(data.shape[0]):\n",
    "            if target[i] not in self.condition:\n",
    "                self.condition[target[i]] = dict(zip([i for i in range(data.shape[1])], [{} for _ in range(data.shape[1])]))\n",
    "                self.nbLabels[target[i]] = 1\n",
    "            else:\n",
    "                self.nbLabels[target[i]] += 1\n",
    "            for j in range(data.shape[1]):\n",
    "                if data[i][j] not in self.condition[target[i]][j]:\n",
    "                    self.condition[target[i]][j][data[i][j]] = 1\n",
    "                else:\n",
    "                    self.condition[target[i]][j][data[i][j]] += 1\n",
    "           \n",
    "        for label in self.nbLabels:\n",
    "            self.prior[label] = self.nbLabels[label] / data.shape[0]\n",
    "            for j in range(data.shape[1]):\n",
    "                for attr_value in self.condition[label][j]:\n",
    "                    self.condition[label][j][attr_value] = (self.condition[label][j][attr_value] + self.alpha)/(self.nbLabels[label]+ self.alpha * data.shape[1])\n",
    "    \n",
    "    \n",
    "    # Prediction is then done by finding \n",
    "    # the argmax over product of probabilities p(C_k).p(x1 | C_k)...p(xn | C_k)\n",
    "    def predict(self, test):\n",
    "        x = np.array(test)\n",
    "        length = x.shape[0]\n",
    "        y_hat = np.zeros((length, ))  \n",
    "        for i in range(length):\n",
    "            proba = dict()\n",
    "            probas = []\n",
    "            for label in self.nbLabels:\n",
    "                product = -self.prior[label]\n",
    "                for j in range(x.shape[1]):\n",
    "                    product *= self.condition[label][j].get(x[i][j], self.alpha /(self.nbLabels[label]+self.alpha*x.shape[1]))\n",
    "                heapq.heappush(probas, product)\n",
    "                proba[product] = label\n",
    "            y_hat[i] = proba[probas[0]]\n",
    "        return y_hat\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"NBC(alpha={})\".format(self.alpha)\n",
    "    def __str__(self):\n",
    "        return \"NBC(alpha={})\".format(self.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[51  0  0  0  1  0  1  0  0  0]\n",
      " [ 0 42  5  0  0  1  0  0  1  1]\n",
      " [ 0  0 45  0  0  0  0  0  2  0]\n",
      " [ 0  0  1 48  0  0  0  0  2  3]\n",
      " [ 0  0  0  0 59  0  0  1  0  0]\n",
      " [ 0  1  0  1  2 48  1  0  0 13]\n",
      " [ 0  0  0  0  1  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 54  0  0]\n",
      " [ 0  2  0  1  0  1  0  0 39  0]\n",
      " [ 0  0  0  2  1  1  0  1  4 50]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.93      0.84      0.88        50\n",
      "           2       0.88      0.96      0.92        47\n",
      "           3       0.92      0.89      0.91        54\n",
      "           4       0.92      0.98      0.95        60\n",
      "           5       0.92      0.73      0.81        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       0.96      0.98      0.97        55\n",
      "           8       0.81      0.91      0.86        43\n",
      "           9       0.75      0.85      0.79        59\n",
      "\n",
      "    accuracy                           0.90       540\n",
      "   macro avg       0.91      0.91      0.90       540\n",
      "weighted avg       0.91      0.90      0.90       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbc = NBC(0.1)\n",
    "nbc.fit(x_digits_train, y_digits_train)\n",
    "y_hat = nbc.predict(x_digits_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_digits_test, y_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_digits_test, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[51  0  0  0  1  1  0  0  0  0]\n",
      " [ 0 39  5  0  0  0  0  0  4  2]\n",
      " [ 0  2 42  0  0  0  0  0  3  0]\n",
      " [ 0  0  1 47  0  0  0  1  4  1]\n",
      " [ 0  2  0  0 55  0  0  3  0  0]\n",
      " [ 0  1  0  0  2 50  1  0  1 11]\n",
      " [ 1  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 54  0  0]\n",
      " [ 0  2  0  0  0  1  0  0 40  0]\n",
      " [ 0  1  0  4  0  1  0  3  1 49]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        53\n",
      "           1       0.83      0.78      0.80        50\n",
      "           2       0.88      0.89      0.88        47\n",
      "           3       0.92      0.87      0.90        54\n",
      "           4       0.95      0.92      0.93        60\n",
      "           5       0.93      0.76      0.83        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       0.89      0.98      0.93        55\n",
      "           8       0.75      0.93      0.83        43\n",
      "           9       0.78      0.83      0.80        59\n",
      "\n",
      "    accuracy                           0.89       540\n",
      "   macro avg       0.89      0.89      0.89       540\n",
      "weighted avg       0.89      0.89      0.89       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbc = NBC(1)\n",
    "nbc.fit(x_sum_train, y_sum_train)\n",
    "y_sum_hat = nbc.predict(x_sum_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_sum_test, y_sum_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_sum_test, y_sum_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST_Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  0   0   0   0   0   0   0 164   0   0]\n",
      " [  0  40   0   0   0   0   0 112   0   0]\n",
      " [  0   0   0   0   0   0   0 155   0   0]\n",
      " [  0   0   0   0   0   0   0 154   0   0]\n",
      " [  0   0   0   0   0   0   0 143   0   0]\n",
      " [  0   0   0   0   0   0   0 141   0   0]\n",
      " [  0   0   0   0   0   0   0 143   0   0]\n",
      " [  0   0   0   0   0   0   0 158   0   0]\n",
      " [  0   0   0   0   0   0   0 132   0   0]\n",
      " [  0   0   0   0   0   0   0 158   0   0]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       164\n",
      "           1       1.00      0.26      0.42       152\n",
      "           2       0.00      0.00      0.00       155\n",
      "           3       0.00      0.00      0.00       154\n",
      "           4       0.00      0.00      0.00       143\n",
      "           5       0.00      0.00      0.00       141\n",
      "           6       0.00      0.00      0.00       143\n",
      "           7       0.11      1.00      0.20       158\n",
      "           8       0.00      0.00      0.00       132\n",
      "           9       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.13      1500\n",
      "   macro avg       0.11      0.13      0.06      1500\n",
      "weighted avg       0.11      0.13      0.06      1500\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nbc = NBC(1)\n",
    "nbc = NBC(2)\n",
    "nbc.fit(x_light_train, y_light_train)\n",
    "y_light_hat = nbc.predict(x_light_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_light_test, y_light_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_light_test, y_light_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import math\n",
    "\n",
    "class GNB:\n",
    "    def __init__(self, epsilon = 0):\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.nbLabels = dict()\n",
    "        self.prior = dict()\n",
    "\n",
    "    def pdf(self, x, mean, std):\n",
    "        exp = math.exp(-((x - mean) ** 2 / (2 * std ** 2)))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * std)) * exp\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        data = np.array(data)\n",
    "        target = np.array(target)\n",
    "        self.means = dict()\n",
    "        self.std = dict()\n",
    "    \n",
    "        for i in range(data.shape[0]):\n",
    "            if target[i] not in self.nbLabels:\n",
    "                self.nbLabels[target[i]] = 1 \n",
    "                self.means[target[i]] = np.zeros(data.shape[1])\n",
    "            else:\n",
    "                self.nbLabels[target[i]] += 1\n",
    "            self.means[target[i]] += self.epsilon + data[i]\n",
    "                         \n",
    "        for label in self.nbLabels:\n",
    "            self.means[label] /= self.nbLabels[label]\n",
    "            self.prior[label] = self.nbLabels[label] / data.shape[0]\n",
    "    \n",
    "        for i in range(data.shape[0]):\n",
    "            diff = np.longdouble(data[i] - self.means[target[i]])\n",
    "            if target[i] not in self.std:\n",
    "                self.std[target[i]] = np.zeros(data.shape[1])\n",
    "            self.std[target[i]] += (diff * diff)/(self.nbLabels[target[i]] - 1)  \n",
    "\n",
    "    # the argmax over product of probabilities p(C_k).p(x1 | C_k)...p(xn | C_k)\n",
    "    def predict(self, test):\n",
    "        x = np.array(test)\n",
    "        length = x.shape[0]\n",
    "        y_hat = np.zeros((length, ))  \n",
    "        for i in range(length):\n",
    "            proba = dict()\n",
    "            probas = []\n",
    "            for label in self.nbLabels:\n",
    "                product = np.longdouble(-self.prior[label])\n",
    "                for j in range(x.shape[1]):\n",
    "                      product *= self.pdf(x[i][j], self.means[label][j], math.sqrt(self.std[label][j]))\n",
    "                heapq.heappush(probas, product)\n",
    "                proba[product] = label\n",
    "            y_hat[i] = proba[probas[0]]\n",
    "        return y_hat\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"GNB(epsilon={})\".format(self.epsilon)\n",
    "    def __str__(self):\n",
    "        return \"GNB(epsilon={})\".format(self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[50  0  0  0  1  0  0  1  0  1]\n",
      " [ 0 36  4  0  0  0  0  0  7  3]\n",
      " [ 0  1 42  0  0  0  0  0  4  0]\n",
      " [ 0  0  2 46  0  0  0  0  4  2]\n",
      " [ 0  0  0  0 59  0  0  0  1  0]\n",
      " [ 0  1  0  1  1 58  1  1  0  3]\n",
      " [ 0  0  0  0  1  1 51  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 53  0  1]\n",
      " [ 0  2  0  0  0  0  0  0 41  0]\n",
      " [ 0  1  1  3  0  2  1  3  3 45]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        53\n",
      "           1       0.88      0.72      0.79        50\n",
      "           2       0.86      0.89      0.88        47\n",
      "           3       0.92      0.85      0.88        54\n",
      "           4       0.95      0.98      0.97        60\n",
      "           5       0.94      0.88      0.91        66\n",
      "           6       0.96      0.96      0.96        53\n",
      "           7       0.91      0.96      0.94        55\n",
      "           8       0.68      0.95      0.80        43\n",
      "           9       0.82      0.76      0.79        59\n",
      "\n",
      "    accuracy                           0.89       540\n",
      "   macro avg       0.89      0.89      0.89       540\n",
      "weighted avg       0.90      0.89      0.89       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GNB(0.1)\n",
    "gnb.fit(x_digits_train, y_digits_train)\n",
    "y_hat = gnb.predict(x_digits_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_digits_test, y_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_digits_test, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[51  0  0  0  1  0  0  1  0  0]\n",
      " [ 0 37  4  0  0  0  0  0  5  4]\n",
      " [ 0  1 45  0  0  0  0  0  1  0]\n",
      " [ 0  0  3 45  0  0  0  0  5  1]\n",
      " [ 0  0  0  0 59  0  0  0  1  0]\n",
      " [ 0  0  0  1  1 61  1  0  1  1]\n",
      " [ 0  0  0  0  1  1 51  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 42  0]\n",
      " [ 0  0  0  6  1  1  0  3  1 47]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.97      0.74      0.84        50\n",
      "           2       0.87      0.96      0.91        47\n",
      "           3       0.87      0.83      0.85        54\n",
      "           4       0.94      0.98      0.96        60\n",
      "           5       0.95      0.92      0.94        66\n",
      "           6       0.98      0.96      0.97        53\n",
      "           7       0.93      0.98      0.96        55\n",
      "           8       0.75      0.98      0.85        43\n",
      "           9       0.87      0.80      0.83        59\n",
      "\n",
      "    accuracy                           0.91       540\n",
      "   macro avg       0.91      0.91      0.91       540\n",
      "weighted avg       0.92      0.91      0.91       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GNB(0.1)\n",
    "gnb.fit(x_sum_train, y_sum_train)\n",
    "y_sum_hat = gnb.predict(x_sum_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_sum_test, y_sum_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_sum_test, y_sum_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST_Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[153   0   2   0   0   2   4   0   2   1]\n",
      " [  0 149   0   0   0   1   1   0   1   0]\n",
      " [  0   6 106  12   1   4  13   1  11   1]\n",
      " [  0   6  16 113   1   2   2   2   6   6]\n",
      " [  0   1   2   0 100   1   3   1   2  33]\n",
      " [  5   5   0  19   5  97   1   1   2   6]\n",
      " [  3   4   0   0   0   2 133   0   1   0]\n",
      " [  0  11   2   0   7   0   0 129   0   9]\n",
      " [  0  14   3   2   1   5   2   0  94  11]\n",
      " [  2   2   0   1  12   1   0   2   1 137]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       164\n",
      "           1       0.75      0.98      0.85       152\n",
      "           2       0.81      0.68      0.74       155\n",
      "           3       0.77      0.73      0.75       154\n",
      "           4       0.79      0.70      0.74       143\n",
      "           5       0.84      0.69      0.76       141\n",
      "           6       0.84      0.93      0.88       143\n",
      "           7       0.95      0.82      0.88       158\n",
      "           8       0.78      0.71      0.75       132\n",
      "           9       0.67      0.87      0.76       158\n",
      "\n",
      "    accuracy                           0.81      1500\n",
      "   macro avg       0.81      0.80      0.80      1500\n",
      "weighted avg       0.82      0.81      0.81      1500\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GNB(20)\n",
    "gnb.fit(x_light_train, y_light_train)\n",
    "y_light_hat = gnb.predict(x_light_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_light_test, y_light_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_light_test, y_light_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST_Light: Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[153   0   1   0   0   3   4   0   2   1]\n",
      " [  0 149   0   0   0   1   1   0   1   0]\n",
      " [  0   7 109  10   4   4   8   1  11   1]\n",
      " [  0   7  14 114   1   3   0   2   7   6]\n",
      " [  0   2   2   0 103   0   2   1   2  31]\n",
      " [  4   5   0  18   4 100   1   1   1   7]\n",
      " [  3   5   0   0   1   3 131   0   0   0]\n",
      " [  0  11   2   0   7   0   0 129   0   9]\n",
      " [  0  16   3   2   2   7   2   0  89  11]\n",
      " [  2   4   0   1  12   1   0   2   1 135]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       164\n",
      "           1       0.72      0.98      0.83       152\n",
      "           2       0.83      0.70      0.76       155\n",
      "           3       0.79      0.74      0.76       154\n",
      "           4       0.77      0.72      0.74       143\n",
      "           5       0.82      0.71      0.76       141\n",
      "           6       0.88      0.92      0.90       143\n",
      "           7       0.95      0.82      0.88       158\n",
      "           8       0.78      0.67      0.72       132\n",
      "           9       0.67      0.85      0.75       158\n",
      "\n",
      "    accuracy                           0.81      1500\n",
      "   macro avg       0.82      0.80      0.81      1500\n",
      "weighted avg       0.82      0.81      0.81      1500\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GNB(0.1)\n",
    "gnb.fit(x_norm_train, y_light_train)\n",
    "y_light_hat = gnb.predict(x_norm_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_light_test, y_light_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_light_test, y_light_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[52  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 37  2  0  0  0  0  2  6  3]\n",
      " [ 0  3 31  0  0  0  1  0 12  0]\n",
      " [ 0  0  2 41  0  0  1  0  8  2]\n",
      " [ 0  0  0  0 51  0  2  7  0  0]\n",
      " [ 0  0  0  1  0 62  1  2  0  0]\n",
      " [ 0  0  0  0  1  1 51  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 54  0  0]\n",
      " [ 0  2  0  0  0  0  0  2 39  0]\n",
      " [ 0  1  1  1  0  2  1  7  4 42]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.86      0.74      0.80        50\n",
      "           2       0.86      0.66      0.75        47\n",
      "           3       0.95      0.76      0.85        54\n",
      "           4       0.98      0.85      0.91        60\n",
      "           5       0.94      0.94      0.94        66\n",
      "           6       0.89      0.96      0.93        53\n",
      "           7       0.72      0.98      0.83        55\n",
      "           8       0.57      0.91      0.70        43\n",
      "           9       0.89      0.71      0.79        59\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.87      0.85      0.85       540\n",
      "weighted avg       0.88      0.85      0.85       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=0.1)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_digits_train, y_digits_train)\n",
    "y_hat = gnb.predict(x_digits_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_digits_test, y_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_digits_test, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKitLearn digits summarised¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[51  0  0  0  1  1  0  0  0  0]\n",
      " [ 0 36  5  0  0  0  0  0  6  3]\n",
      " [ 0  1 44  0  0  0  0  0  2  0]\n",
      " [ 0  0  1 47  0  0  0  1  4  1]\n",
      " [ 0  0  0  0 59  0  0  1  0  0]\n",
      " [ 0  0  0  0  1 59  1  0  0  5]\n",
      " [ 0  0  0  0  1  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  1]\n",
      " [ 0  2  0  0  0  1  0  1 39  0]\n",
      " [ 0  0  0  6  0  1  0  3  1 48]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.92      0.72      0.81        50\n",
      "           2       0.88      0.94      0.91        47\n",
      "           3       0.89      0.87      0.88        54\n",
      "           4       0.95      0.98      0.97        60\n",
      "           5       0.95      0.89      0.92        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       0.90      0.98      0.94        55\n",
      "           8       0.75      0.91      0.82        43\n",
      "           9       0.83      0.81      0.82        59\n",
      "\n",
      "    accuracy                           0.91       540\n",
      "   macro avg       0.91      0.90      0.90       540\n",
      "weighted avg       0.91      0.91      0.91       540\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=0.1)\n",
    "# gnb = GaussianNB()\n",
    "gnb.fit(x_sum_train, y_sum_train)\n",
    "y_sum_hat = gnb.predict(x_sum_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_sum_test, y_sum_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_sum_test, y_sum_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST_Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[156   0   1   0   0   1   2   0   3   1]\n",
      " [  0 149   0   0   0   1   1   0   1   0]\n",
      " [  0   6 110  12   1   1  12   1  12   0]\n",
      " [  0   7  14 115   1   0   1   2   8   6]\n",
      " [  0   2   2   0  95   0   4   0   3  37]\n",
      " [  7   6   0  21   3  94   1   1   4   4]\n",
      " [  3   5   0   0   0   1 133   0   1   0]\n",
      " [  0  12   2   0   5   0   0 128   1  10]\n",
      " [  1  13   2   3   0   2   2   0  99  10]\n",
      " [  2   4   0   1  11   1   0   2   1 136]] \n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       164\n",
      "           1       0.73      0.98      0.84       152\n",
      "           2       0.84      0.71      0.77       155\n",
      "           3       0.76      0.75      0.75       154\n",
      "           4       0.82      0.66      0.73       143\n",
      "           5       0.93      0.67      0.78       141\n",
      "           6       0.85      0.93      0.89       143\n",
      "           7       0.96      0.81      0.88       158\n",
      "           8       0.74      0.75      0.75       132\n",
      "           9       0.67      0.86      0.75       158\n",
      "\n",
      "    accuracy                           0.81      1500\n",
      "   macro avg       0.82      0.81      0.81      1500\n",
      "weighted avg       0.82      0.81      0.81      1500\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=0.1)\n",
    "# gnb = GaussianNB()\n",
    "gnb.fit(x_light_train, y_light_train)\n",
    "y_light_hat = gnb.predict(x_light_test)\n",
    "# Evaluation:\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_light_test, y_light_hat), \"\\n\")\n",
    "print(\"classification report:\\n\", classification_report(y_light_test, y_light_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
