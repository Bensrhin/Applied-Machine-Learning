{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciKitLearn DecisionTreeClassifier (based on CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Loading the digits dataset from the datasets provided in SciKitLearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "# Features\n",
    "x = digits.data\n",
    "# Labels\n",
    "y = digits.target\n",
    "# images\n",
    "images = digits.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "digits.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([('y', 's', 'r'), ('y', 's', 'r'), ('g', 's', 'i'), ('g', 'l', 'i'), ('y', 'l', 'r'), ('y', 's', 'r'), ('y', 's', 'r'), ('y', 's', 'r'), ('g', 's', 'r'), ('y', 'l', 'r'), ('y', 'l', 'r'), ('y', 'l', 'r'), ('y', 'l', 'r'), ('y', 'l', 'r'), ('y', 's', 'i'), ('y', 'l', 'i')])\n",
    "attributes = dict([('color', ['y', 'g', 'b']), ('size', ['s', 'l']), ('shape', ['r', 'i'])])\n",
    "target = np.array(['+', '-', '+', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '-', '+', '+']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['y', 's', 'r'],\n",
       "       ['y', 's', 'r'],\n",
       "       ['g', 's', 'i'],\n",
       "       ['g', 'l', 'i'],\n",
       "       ['y', 'l', 'r'],\n",
       "       ['y', 's', 'r'],\n",
       "       ['y', 's', 'r'],\n",
       "       ['y', 's', 'r'],\n",
       "       ['g', 's', 'r'],\n",
       "       ['y', 'l', 'r'],\n",
       "       ['y', 'l', 'r'],\n",
       "       ['y', 'l', 'r'],\n",
       "       ['y', 'l', 'r'],\n",
       "       ['y', 'l', 'r'],\n",
       "       ['y', 's', 'i'],\n",
       "       ['y', 'l', 'i']], dtype='<U1')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes['color']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 6, 12],\n",
    "                [5, 3, 8],\n",
    "                 [5, 3, 11],\n",
    "                [10, 6, 0]])\n",
    "e = np.array(data, dtype='<U21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '6', '12'],\n",
       "       ['5', '3', '8'],\n",
       "       ['5', '3', '11'],\n",
       "       ['10', '6', '0']], dtype='<U21')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'r': array([['y', 's'],\n",
       "        ['y', 's'],\n",
       "        ['y', 'l'],\n",
       "        ['y', 's'],\n",
       "        ['y', 's'],\n",
       "        ['y', 's'],\n",
       "        ['g', 's'],\n",
       "        ['y', 'l'],\n",
       "        ['y', 'l'],\n",
       "        ['y', 'l'],\n",
       "        ['y', 'l'],\n",
       "        ['y', 'l']], dtype='<U1'), 'i': array([['g', 's'],\n",
       "        ['g', 'l'],\n",
       "        ['y', 's'],\n",
       "        ['y', 'l']], dtype='<U1')}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = {}\n",
    "targets = {}\n",
    "# idx = 0\n",
    "# for values in ['y', 'g', 'b']:\n",
    "# idx = 1\n",
    "# for values in ['s', 'l']:  \n",
    "idx = 2\n",
    "for values in ['r', 'i']:\n",
    "    targets[values] = target[values == data[:, idx]]\n",
    "    datas[values] = data[values == data[:, idx]]\n",
    "    datas[values] = np.delete(data[values == data[:, idx]], 2, 1)\n",
    "    print(len(targets[values]))\n",
    "#     if len(targets[values]) != 0:\n",
    "#         datas[values] = np.delete(data[values == data[:, idx]], 0, idx)\n",
    "#     else:\n",
    "#         datas[values] = data[values == data[:, idx]]\n",
    "    \n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "d = collections.OrderedDict()\n",
    "# d['a'] = 2\n",
    "# d['b'] = 1\n",
    "# d['c'] = 5\n",
    "# d['d'] = 6\n",
    "# for key in d.keys():\n",
    "#     print(key)\n",
    "if (not d):\n",
    "    print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': array(['+', '-', '+', '+', '+', '+', '-', '+'], dtype='<U1'),\n",
       " 'l': array(['-', '+', '-', '+', '-', '-', '-', '+'], dtype='<U1')}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = {}\n",
    "targets = {}\n",
    "for values in attributes['size']:\n",
    "    datas[values] = data[values == data[:, 1]]\n",
    "    targets[values] = target[values == data[:, 1]]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array of int target names to array of str\n",
    "import numpy as np\n",
    "t = digits.target_names\n",
    "target_names=np.array(t).astype('str').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Spliting the data set into 70% training data and 30% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test, img_tr, img_ts = train_test_split(x, y, images, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 37518,\n",
       " 4.0: 2147,\n",
       " 12.0: 2460,\n",
       " 16.0: 6945,\n",
       " 8.0: 2337,\n",
       " 15.0: 2874,\n",
       " 1.0: 2774,\n",
       " 14.0: 2420,\n",
       " 7.0: 1764,\n",
       " 6.0: 1672,\n",
       " 10.0: 1819,\n",
       " 13.0: 2397,\n",
       " 2.0: 2197,\n",
       " 3.0: 1985,\n",
       " 9.0: 1745,\n",
       " 5.0: 1857,\n",
       " 11.0: 1889}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = {}\n",
    "x_train[1, 9]\n",
    "for i in range(1200):\n",
    "    for j in range(64):\n",
    "        if x_train[i,j] not in att:\n",
    "            att[x_train[i,j]] = 1\n",
    "        else:\n",
    "            att[x_train[i,j]] += 1\n",
    "att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Set up a DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "# train a decision tree classifier for the digits dataset based on the training data\n",
    "classifier = classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce a plot of the tree with GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digits.pdf'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(classifier, out_file=None,   \n",
    "                      class_names=target_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"digits\") \n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test the classifier with the remaining test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the labels of the test set\n",
    "y_hat = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        63\n",
      "           1       0.85      0.73      0.79        63\n",
      "           2       0.87      0.88      0.87        51\n",
      "           3       0.83      0.77      0.80        56\n",
      "           4       0.90      0.96      0.93        49\n",
      "           5       0.91      0.87      0.89        61\n",
      "           6       0.91      0.93      0.92        55\n",
      "           7       0.87      0.94      0.90        48\n",
      "           8       0.66      0.69      0.67        48\n",
      "           9       0.78      0.85      0.81        46\n",
      "\n",
      "    accuracy                           0.86       540\n",
      "   macro avg       0.85      0.86      0.85       540\n",
      "weighted avg       0.86      0.86      0.86       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61  0  1  0  0  1  0  0  0  0]\n",
      " [ 1 46  1  2  2  1  2  0  7  1]\n",
      " [ 0  2 45  1  0  0  1  0  0  2]\n",
      " [ 0  0  3 43  0  1  0  1  4  4]\n",
      " [ 0  0  0  0 47  1  0  1  0  0]\n",
      " [ 0  1  0  0  1 53  1  1  1  3]\n",
      " [ 0  1  1  0  0  0 51  0  2  0]\n",
      " [ 0  1  0  0  1  0  0 45  1  0]\n",
      " [ 2  3  1  4  1  0  1  2 33  1]\n",
      " [ 0  0  0  2  0  1  0  2  2 39]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **min_samples_split** parameter:\n",
    "will evaluate the number of samples in the node, and \n",
    "if the number is less than the minimum the split will be avoided and the node will be a leaf.\n",
    "\n",
    "The **min_samples_leaf** parameter checks before the node is generated, that is, \n",
    "if the possible split results in a child with fewer samples, the split will be avoided \n",
    "(since the minimum number of samples for the child to be a leaf has not been reached) \n",
    "and the node will be replaced by a leaf.\n",
    "\n",
    "In all cases, when we have samples with more than one Class in a leaf, the Final Class will be the most likely to happen, according to the samples that reached it in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best splitter: best\n",
      "Best Criterion: entropy\n",
      "Best min_samples_split: 2\n",
      "Best min_samples_leaf: 1\n",
      "Best max_depth: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X, y = x_train, y_train\n",
    "\n",
    "# Creating a DecisionTreeClassifier\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "# Steps : training a Decision Tree Classifier on the data.\n",
    "pipe = Pipeline(steps=[('dec_tree', dec_tree)])\n",
    "\n",
    "\n",
    "# Creating lists of parameter for Decision Tree Classifier\n",
    "splitter = [\"best\", \"random\"]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,4,6,8,10,12, None]\n",
    "splits = [2, 5, 8, 10]\n",
    "leaves = [1, 2, 3, 4, 5, 6]\n",
    "# Creating a dictionary of all the parameter options \n",
    "# Note that we can access the parameters of steps of a pipeline by using '__’\n",
    "parameters = dict(#pca__n_components=n_components,\n",
    "                  dec_tree__splitter=splitter,\n",
    "                  dec_tree__criterion=criterion,\n",
    "                  dec_tree__min_samples_split=splits,\n",
    "                  dec_tree__min_samples_leaf=leaves,\n",
    "                  dec_tree__max_depth=max_depth)\n",
    "\n",
    "# Creating a grid search object\n",
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "\n",
    "# Fitting the grid search\n",
    "clf_GS.fit(X, y)\n",
    "\n",
    "# Viewing The Best Parameters\n",
    "print('Best splitter:', clf_GS.best_estimator_.get_params()['dec_tree__splitter'])\n",
    "print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best min_samples_split:', clf_GS.best_estimator_.get_params()['dec_tree__min_samples_split'])\n",
    "print('Best min_samples_leaf:', clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf'])\n",
    "print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the parameters of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        63\n",
      "           1       0.87      0.86      0.86        63\n",
      "           2       0.89      0.82      0.86        51\n",
      "           3       0.89      0.75      0.82        56\n",
      "           4       0.90      0.88      0.89        49\n",
      "           5       0.93      0.92      0.93        61\n",
      "           6       0.85      0.93      0.89        55\n",
      "           7       0.91      0.88      0.89        48\n",
      "           8       0.83      0.92      0.87        48\n",
      "           9       0.81      0.91      0.86        46\n",
      "\n",
      "    accuracy                           0.88       540\n",
      "   macro avg       0.88      0.88      0.88       540\n",
      "weighted avg       0.89      0.88      0.88       540\n",
      "\n",
      "[[61  0  0  0  0  0  1  0  0  1]\n",
      " [ 0 54  2  1  1  2  0  1  0  2]\n",
      " [ 0  2 42  2  0  0  1  1  3  0]\n",
      " [ 1  2  1 42  0  0  4  1  2  3]\n",
      " [ 3  1  0  0 43  1  0  1  0  0]\n",
      " [ 0  0  0  0  0 56  1  0  0  4]\n",
      " [ 0  1  0  0  2  0 51  0  1  0]\n",
      " [ 0  1  1  0  2  0  0 42  2  0]\n",
      " [ 0  1  1  0  0  0  2  0 44  0]\n",
      " [ 0  0  0  2  0  1  0  0  1 42]]\n"
     ]
    }
   ],
   "source": [
    "classifier = tree.DecisionTreeClassifier(splitter=\"best\",\n",
    "                                         criterion=\"entropy\",\n",
    "                                         min_samples_split=2,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         max_depth=None)\n",
    "# training\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "\n",
    "# predicting the labels of the test set\n",
    "y_hat = classifier.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(confusion_matrix(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
